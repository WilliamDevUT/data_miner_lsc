"""
Predictor de se√±as con sistema de rutas relativas y detecci√≥n autom√°tica de frames.
Incluye validaci√≥n contra Whisper y corte de clips de video.
Este script puede ejecutarse independientemente del data_miner.
"""
import json
import numpy as np
import os
import re
from datetime import datetime
from tensorflow import keras
from moviepy.editor import VideoFileClip
from pathlib import Path
import sys


# ======================================================
# CONFIGURACI√ìN DE RUTAS PARA IMPORTAR CONFIG
# ======================================================
# Obtener el directorio del script actual (ai_trainer)
script_dir = Path(__file__).resolve().parent
print(f"üìÇ Directorio del script: {script_dir}")

# Subir un nivel para llegar al directorio ra√≠z del proyecto (new)
project_root = script_dir.parent
print(f"üìÇ Directorio ra√≠z del proyecto: {project_root}")

# A√±adir el directorio ra√≠z al path de Python
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Verificar que config.py existe
config_path = project_root / "config.py"
print(f"üìÇ Buscando config en: {config_path}")
print(f"üìÇ ¬øExiste config.py?: {config_path.exists()}")

# Importar configuraci√≥n compartida
try:
    from config import (
        get_model_paths, get_latest_video_dir, get_video_files,
        load_processing_state, save_processing_state,
        ensure_directories, validate_environment,
        PREDICTIONS_OUTPUT, PREDICTION_THRESHOLD, MODEL_FRAMES,
        VALIDATED_VIDEOS_DIR, VALIDATED_KEYPOINTS_DIR,
        UNKNOWN_VIDEOS_DIR, UNKNOWN_KEYPOINTS_DIR,
        get_whisper_and_video_paths 
    )
    CONFIG_AVAILABLE = True
    print("‚úì Config compartido cargado exitosamente")
except ImportError as e:
    print(f"‚ö† No se pudo importar config.py: {e}")
    print(f"‚ö† Usando configuraci√≥n por defecto")
    CONFIG_AVAILABLE = False
    PREDICTIONS_OUTPUT = Path("./output")
    PREDICTION_THRESHOLD = 0.7
    MODEL_FRAMES = 30

# Importar constantes del proyecto original (si est√°n disponibles)
try:
    from constants import words_text
    print(f"‚úì Constantes cargadas: {len(words_text)} palabras disponibles")
except ImportError:
    print("‚ö† constants.py no disponible, usando diccionario b√°sico")
    words_text = {}


# ======================================================
# CLASE: FileUtils
# ======================================================
class FileUtils:
    """Utilidades para manejo de archivos y carpetas."""
    
    @staticmethod
    def create_folder_if_not_exists(path):
        """Crea una carpeta si no existe."""
        path = Path(path)
        if not path.exists():
            path.mkdir(parents=True, exist_ok=True)
            print(f"  [INFO] Carpeta creada: {path}")
    
    @staticmethod
    def clean_filename(name):
        """
        Limpia un string para que sea un nombre de archivo v√°lido.
        Convierte a min√∫sculas y elimina caracteres inv√°lidos.
        """
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            name = name.replace(char, '_')
        # Eliminar espacios al inicio/final, convertir a min√∫sculas, eliminar comas finales
        name = name.strip().lower().rstrip(',')
        return name
    
    @staticmethod
    def get_next_video_number(folder_path):
        """
        Busca en la carpeta todos los archivos se√±a_N.mp4
        y devuelve el siguiente n√∫mero disponible.
        """
        folder_path = Path(folder_path)
        if not folder_path.exists():
            return 1
        
        files = list(folder_path.iterdir())
        existing_numbers = []
        
        # Patr√≥n para buscar: se√±a_N.mp4
        pattern = re.compile(r'se√±a_(\d+)\.mp4')
        
        for file in files:
            match = pattern.match(file.name)
            if match:
                number = int(match.group(1))
                existing_numbers.append(number)
        
        return max(existing_numbers) + 1 if existing_numbers else 1


# ======================================================
# FUNCI√ìN AUXILIAR: Normalizar Keypoints
# ======================================================
def normalize_keypoints(keypoints_sequence, target_frames):
    """
    Normaliza una secuencia de keypoints a un n√∫mero fijo de frames.
    
    Args:
        keypoints_sequence: Lista de keypoints (frames variables)
        target_frames: N√∫mero de frames objetivo
    
    Returns:
        Array numpy normalizado con shape (target_frames, num_keypoints)
    """
    keypoints_array = np.array(keypoints_sequence)
    current_frames = len(keypoints_array)
    
    if current_frames == 0:
        num_keypoints = 1662  # Por defecto
        return np.zeros((target_frames, num_keypoints))
    
    if current_frames == target_frames:
        return keypoints_array
    
    elif current_frames > target_frames:
        indices = np.linspace(0, current_frames - 1, target_frames, dtype=int)
        return keypoints_array[indices]
    
    else:
        indices_original = np.arange(current_frames)
        indices_target = np.linspace(0, current_frames - 1, target_frames)
        
        normalized = np.zeros((target_frames, keypoints_array.shape[1]))
        for i in range(keypoints_array.shape[1]):
            normalized[:, i] = np.interp(indices_target, indices_original, keypoints_array[:, i])
        
        return normalized


# ======================================================
# FUNCI√ìN AUXILIAR: Detectar frames del modelo
# ======================================================
def detect_model_frames(model):
    """
    Detecta el n√∫mero de frames que espera el modelo.
    
    Args:
        model: Modelo Keras cargado
    
    Returns:
        int: N√∫mero de frames detectados
    """
    try:
        input_shape = model.input_shape
        if len(input_shape) > 1:
            return input_shape[1]
    except:
        pass
    
    return MODEL_FRAMES  # Valor por defecto del config


# ======================================================
# CLASE: WhisperTranscriptionLoader
# ======================================================
class WhisperTranscriptionLoader:
    """Cargador de transcripciones de Whisper desde JSON."""
    
    def __init__(self, json_path):
        """
        Inicializa el cargador de transcripciones.
        
        Args:
            json_path: Ruta al archivo JSON de Whisper
        """
        self.json_path = Path(json_path)
        self.words = []
        self._load_transcription()
    
    def _load_transcription(self):
        """Carga las transcripciones desde el JSON de Whisper."""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.words = data.get('words', [])
            
            print(f"\nüìù Transcripci√≥n Whisper cargada")
            print(f"   Total de palabras: {len(self.words)}")
            
        except Exception as e:
            print(f"‚ùå Error al cargar transcripci√≥n Whisper: {e}")
            raise
    
    def get_word_at_time(self, time):
        """
        Obtiene la palabra que se estaba diciendo en un momento espec√≠fico.
        
        Args:
            time: Tiempo en segundos
        
        Returns:
            Diccionario con la palabra o None si no hay coincidencia
        """
        for word_data in self.words:
            if word_data['start'] <= time <= word_data['end']:
                return word_data
        return None
    
    def get_words_in_range(self, start_time, end_time):
        """
        Obtiene todas las palabras en un rango de tiempo.
        
        Args:
            start_time: Tiempo de inicio en segundos
            end_time: Tiempo de fin en segundos
        
        Returns:
            Lista de palabras en el rango
        """
        words_in_range = []
        for word_data in self.words:
            if start_time <= word_data['start'] <= end_time:
                words_in_range.append(word_data)
        return words_in_range


# ======================================================
# CLASE: VideoClipper
# ======================================================
class VideoClipper:
    """Cortador de clips de video."""
    
    def __init__(self, video_path):
        """
        Inicializa el cortador de video.
        
        Args:
            video_path: Ruta al video fuente
        """
        self.video_path = Path(video_path)
        
        if not self.video_path.exists():
            raise FileNotFoundError(f"No se encontr√≥ el video: {video_path}")
        
        # Obtener duraci√≥n del video
        with VideoFileClip(str(self.video_path)) as video:
            self.video_duration = video.duration
        
        print(f"\nüé¨ Video cargado: {self.video_path.name}")
        print(f"   Duraci√≥n: {self.video_duration:.2f}s")
    
    def cut_clip(self, start_time, end_time, output_folder):
        """
        Corta un clip de video y lo guarda con numeraci√≥n autom√°tica.
        
        Args:
            start_time: Tiempo de inicio en segundos
            end_time: Tiempo de fin en segundos
            output_folder: Carpeta donde guardar el clip
        
        Returns:
            str: Nombre del archivo guardado o None si fall√≥
        """
        try:
            output_folder = Path(output_folder)
            
            # Obtener el siguiente n√∫mero de video disponible
            video_number = FileUtils.get_next_video_number(output_folder)
            
            # Construir nombre del archivo: se√±a_N.mp4
            filename = f"se√±a_{video_number}.mp4"
            output_path = output_folder / filename
            
            # Ajustar tiempos si exceden la duraci√≥n del video
            if start_time >= self.video_duration:
                print(f"  [ERROR] Tiempo de inicio ({start_time:.2f}s) excede la duraci√≥n del video ({self.video_duration:.2f}s)")
                return None
            
            if end_time > self.video_duration:
                print(f"  [AVISO] Tiempo de fin ajustado de {end_time:.2f}s a {self.video_duration:.2f}s")
                end_time = self.video_duration
            
            # Cortar y guardar clip
            with VideoFileClip(str(self.video_path)) as video:
                clip = video.subclip(start_time, end_time)
                clip.write_videofile(
                    str(output_path), 
                    codec="libx264", 
                    audio_codec="aac", 
                    verbose=False, 
                    logger=None
                )
            
            print(f"  [‚úì CLIP GUARDADO] {filename}")
            return filename
            
        except Exception as e:
            print(f"  [ERROR] No se pudo cortar el clip: {e}")
            return None


# ======================================================
# CLASE: SignPredictor
# ======================================================
class SignPredictor:
    """Clase para realizar predicciones de se√±as desde JSON de keypoints."""
    
    def __init__(self, model_path, words_json_path=None, threshold=None):
        """
        Inicializa el predictor.
        
        Args:
            model_path: Path al modelo Keras
            words_json_path: Path al words.json del modelo (opcional)
            threshold: Umbral de confianza (0.0 - 1.0)
        """
        self.model_path = Path(model_path)
        self.threshold = threshold or PREDICTION_THRESHOLD
        self.model = None
        self.all_detections = []
        self.model_frames = None  # Se detectar√° autom√°ticamente
        
        # Cargar word_ids
        if words_json_path and Path(words_json_path).exists():
            self.words_json_path = Path(words_json_path)
            with open(words_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.word_ids = data.get('word_ids', [])
        else:
            self.words_json_path = None
            self.word_ids = []
            print("‚ö† No se carg√≥ words.json, usando √≠ndices num√©ricos")
        
        print(f"\n{'='*70}")
        print(f"ü§ñ INICIALIZANDO PREDICTOR DE SE√ëAS")
        print(f"{'='*70}")
        print(f"Modelo: {self.model_path}")
        if self.words_json_path:
            print(f"Words JSON: {self.words_json_path}")
        print(f"Clases disponibles: {len(self.word_ids) if self.word_ids else 'N/A'}")
        print(f"Umbral: {self.threshold * 100}%")
        
        self._load_model()
    
    def _load_model(self):
        """Carga el modelo Keras - VERSI√ìN SIMPLIFICADA."""
        try:
            if not self.model_path.exists():
                raise FileNotFoundError(f"No se encontr√≥ el modelo: {self.model_path}")
            
            print(f"\nüì¶ Cargando modelo...")
            self.model = keras.models.load_model(str(self.model_path))
            print(f"‚úì Modelo cargado exitosamente")
            
            # Detectar frames del modelo
            self.model_frames = detect_model_frames(self.model)
            
            print(f"  ‚Ä¢ Input shape: {self.model.input_shape}")
            print(f"  ‚Ä¢ Output shape: {self.model.output_shape}")
            print(f"  ‚Ä¢ Frames detectados: {self.model_frames}")
            
        except Exception as e:
            print(f"‚ùå Error al cargar modelo: {e}")
            raise
    
    def predict_from_json(self, json_path, save_results=True, output_dir=None):
        """
        Procesa todos los segmentos del JSON y realiza predicciones.
        
        Args:
            json_path: Path al archivo JSON con keypoints
            save_results: Guardar resultados en JSON
            output_dir: Directorio para guardar resultados
        
        Returns:
            Lista de detecciones
        """
        json_path = Path(json_path)
        
        print(f"\n{'='*70}")
        print(f"üéØ PROCESANDO SEGMENTOS")
        print(f"{'='*70}")
        print(f"Archivo: {json_path}")
        print(f"Frames por predicci√≥n: {self.model_frames}")
        
        # Cargar JSON
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                segments_data = json.load(f)
            print(f"‚úì JSON cargado: {len(segments_data)} segmentos")
        except Exception as e:
            print(f"‚ùå Error al cargar JSON: {e}")
            return None
        
        # Reiniciar detecciones
        self.all_detections = []
        total_segments = len(segments_data)
        
        # Procesar cada segmento
        for idx, segment in enumerate(segments_data):
            start_time = segment.get('start_time', 0)
            end_time = segment.get('end_time', 0)
            keypoints_sequence = segment.get('keypoints', [])
            
            # Mostrar progreso
            if (idx + 1) % 10 == 0 or idx == 0:
                print(f"\nüìç Procesando segmento {idx + 1}/{total_segments}")
                print(f"   Tiempo: {start_time}s - {end_time}s")
                print(f"   Frames en segmento: {len(keypoints_sequence)}")
            
            if len(keypoints_sequence) == 0:
                if idx < 3:
                    print(f"   ‚ö† Segmento vac√≠o, saltando...")
                continue
            
            # Predicci√≥n
            try:
                # Normalizar a la cantidad exacta de frames que espera el modelo
                kp_normalized = normalize_keypoints(keypoints_sequence, self.model_frames)
                
                # Realizar predicci√≥n
                res = self.model.predict(np.expand_dims(kp_normalized, axis=0), verbose=0)[0]
                
                max_idx = np.argmax(res)
                confidence = res[max_idx] * 100
                
                if confidence > self.threshold * 100:
                    # Obtener palabra
                    if self.word_ids and max_idx < len(self.word_ids):
                        word_id = self.word_ids[max_idx].split('-')[0]
                        palabra_detectada = words_text.get(word_id, f"palabra_{max_idx}")
                    else:
                        palabra_detectada = f"clase_{max_idx}"
                    
                    detection = {
                        'segmento': idx + 1,
                        'tiempo_start': round(start_time, 2),
                        'tiempo_fin': round(end_time, 2),
                        'palabra_detectada': palabra_detectada,
                        'confianza': round(confidence, 2),
                        'frames_procesados': len(keypoints_sequence),
                        'frames_normalizados': self.model_frames,
                        'keypoints': keypoints_sequence  # Guardar keypoints para extraer despu√©s
                    }
                    self.all_detections.append(detection)
                    
                    print(f"   ‚úì Detectado: '{palabra_detectada}' | Confianza: {confidence:.2f}%")
                else:
                    if idx < 3:
                        print(f"   ‚úó Confianza baja: {confidence:.2f}%")
            
            except Exception as e:
                if idx < 3:
                    print(f"   ‚ùå Error en segmento {idx + 1}: {e}")
                continue
        
        # Resumen final
        print(f"\n{'='*70}")
        print(f"üìä RESUMEN DE PREDICCIONES")
        print(f"{'='*70}")
        print(f"Segmentos procesados: {total_segments}")
        print(f"Detecciones v√°lidas: {len(self.all_detections)}")
        print(f"Tasa de detecci√≥n: {(len(self.all_detections) / total_segments * 100):.2f}%")
        print(f"{'='*70}\n")
        
        # Mostrar detecciones
        if self.all_detections:
            print("üé§ PALABRAS DETECTADAS:")
            print("-" * 70)
            for det in self.all_detections:
                print(f"[{det['tiempo_start']}s - {det['tiempo_fin']}s] "
                      f"{det['palabra_detectada']} ({det['confianza']}%)")
            print("-" * 70)
        else:
            print("‚ö† No se detectaron se√±as con suficiente confianza")
        
        # Guardar resultados
        if save_results and self.all_detections:
            output_dir = Path(output_dir) if output_dir else PREDICTIONS_OUTPUT
            self.save_results(output_dir)
        
        return self.all_detections
    
    def save_results(self, output_dir):
        """Guarda los resultados en JSON incluyendo los keypoints de cada detecci√≥n."""
        try:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = output_dir / f"detecciones_{timestamp}.json"
            
            results = {
                'fecha': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'modelo': self.model_path.name,
                'frames_modelo': self.model_frames,
                'umbral_confianza': self.threshold,
                'total_detecciones': len(self.all_detections),
                'detecciones': self.all_detections  # Ya incluye keypoints
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"\nüíæ Resultados guardados en: {output_file}")
            print(f"   ‚úì Guardadas {len(self.all_detections)} detecciones con keypoints")
            return output_file
            
        except Exception as e:
            print(f"‚ùå Error al guardar resultados: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_transcript(self):
        """Genera un transcript ordenado de las palabras detectadas."""
        if not self.all_detections:
            return ""
        
        sorted_detections = sorted(self.all_detections, key=lambda x: x['tiempo_start'])
        words = [det['palabra_detectada'] for det in sorted_detections]
        return " ".join(words)


# ======================================================
# CLASE: SignValidatorAndClipper
# ======================================================
class SignValidatorAndClipper:
    """
    Validador de detecciones de se√±as y cortador de clips.
    Compara detecciones de se√±as con transcripciones de Whisper.
    """
    
    def __init__(self, 
                 detections_json_path,
                 whisper_json_path,
                 video_path,
                 validated_videos_dir,
                 validated_keypoints_dir,
                 unknown_videos_dir,
                 unknown_keypoints_dir,
                 search_window_seconds=10,
                 additional_seconds=5):
        """
        Inicializa el validador y cortador.
        
        Args:
            detections_json_path: Ruta al JSON de detecciones de se√±as
            whisper_json_path: Ruta al JSON de transcripci√≥n Whisper
            video_path: Ruta al video fuente
            validated_videos_dir: Carpeta para videos validados
            validated_keypoints_dir: Carpeta para keypoints validados
            unknown_videos_dir: Carpeta para videos desconocidos
            unknown_keypoints_dir: Carpeta para keypoints desconocidos
            search_window_seconds: Ventana de b√∫squeda hacia atr√°s (segundos)
            additional_seconds: Segundos adicionales despu√©s del fin para clips desconocidos
        """
        self.detections_json_path = Path(detections_json_path)
        self.validated_videos_dir = Path(validated_videos_dir)
        self.validated_keypoints_dir = Path(validated_keypoints_dir)
        self.unknown_videos_dir = Path(unknown_videos_dir)
        self.unknown_keypoints_dir = Path(unknown_keypoints_dir)
        self.search_window_seconds = search_window_seconds
        self.additional_seconds = additional_seconds
        
        # Crear carpetas principales
        FileUtils.create_folder_if_not_exists(validated_videos_dir)
        FileUtils.create_folder_if_not_exists(validated_keypoints_dir)
        FileUtils.create_folder_if_not_exists(unknown_videos_dir)
        FileUtils.create_folder_if_not_exists(unknown_keypoints_dir)
        
        # Cargar detecciones de se√±as
        self._load_detections()
        
        # Cargar transcripci√≥n de Whisper
        self.whisper_loader = WhisperTranscriptionLoader(whisper_json_path)
        
        # Inicializar cortador de video
        self.video_clipper = VideoClipper(video_path)
        
        # Contadores
        self.validated_count = 0
        self.failed_count = 0
        self.remaining_processed = 0
    
    def _load_detections(self):
        """Carga las detecciones desde el JSON."""
        try:
            with open(self.detections_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.detections = data.get('detecciones', [])
            
            print(f"\nüéØ Detecciones cargadas")
            print(f"   Total de detecciones: {len(self.detections)}")
            
        except Exception as e:
            print(f"‚ùå Error al cargar detecciones: {e}")
            raise
    
    def _normalize_text(self, text):
        """Normaliza texto para comparaci√≥n (min√∫sculas, sin puntuaci√≥n)."""
        return re.sub(r'[^\w\s]', '', text).lower().strip()
    
    def _save_keypoints(self, keypoints, word_folder, filename):
        """
        Guarda los keypoints en formato JSON.
        
        Args:
            keypoints: Lista de keypoints del clip
            word_folder: Carpeta de la palabra
            filename: Nombre del archivo (sin extensi√≥n)
        """
        try:
            keypoints_path = word_folder / f"{filename}.json"
            with open(keypoints_path, 'w', encoding='utf-8') as f:
                json.dump(keypoints, f, ensure_ascii=False, indent=2)
            print(f"  [‚úì KEYPOINTS GUARDADOS] {filename}.json")
        except Exception as e:
            print(f"  [ERROR] No se pudieron guardar keypoints: {e}")
    
    def validate_and_clip_detections(self):
        """
        Procesa todas las detecciones: valida contra Whisper y corta clips.
        """
        print(f"\n{'='*80}")
        print(f"üîç INICIANDO VALIDACI√ìN Y CORTE DE CLIPS")
        print(f"{'='*80}")
        
        for idx, detection in enumerate(self.detections):
            detected_word = detection['palabra_detectada']
            start_time = detection['tiempo_start']
            end_time = detection['tiempo_fin']
            keypoints = detection.get('keypoints', [])
            
            print(f"\n[{idx + 1}/{len(self.detections)}] Procesando: '{detected_word}' ({start_time:.2f}s - {end_time:.2f}s)")
            print(f"  [DEBUG] Keypoints en detecci√≥n: {len(keypoints)} frames")
            
            # Definir ventana de b√∫squeda (hacia atr√°s desde start_time)
            search_start = start_time - self.search_window_seconds
            search_end = start_time
            
            # Obtener palabras de Whisper en la ventana temporal
            whisper_words = self.whisper_loader.get_words_in_range(search_start, search_end)
            
            # Normalizar palabra detectada para comparaci√≥n
            normalized_detected = self._normalize_text(detected_word)
            
            # Verificar si la palabra est√° en la transcripci√≥n
            is_validated = any(
                normalized_detected in self._normalize_text(w['word']) 
                for w in whisper_words
            )
            
            if is_validated:
                # PALABRA VALIDADA
                print(f"  [‚úì VALIDADA] Encontrada en transcripci√≥n")
                self.validated_count += 1
                
                # Crear carpeta para la palabra validada
                folder_name = FileUtils.clean_filename(detected_word)
                video_word_folder = self.validated_videos_dir / folder_name
                keypoints_word_folder = self.validated_keypoints_dir / folder_name
                FileUtils.create_folder_if_not_exists(video_word_folder)
                FileUtils.create_folder_if_not_exists(keypoints_word_folder)
                
                # Cortar clip
                filename = self.video_clipper.cut_clip(start_time, end_time, video_word_folder)
                
                # Guardar keypoints DEL SEGMENTO ORIGINAL con el mismo nombre (sin extensi√≥n)
                if filename:
                    filename_base = filename.replace('.mp4', '')
                    if keypoints:
                        self._save_keypoints(keypoints, keypoints_word_folder, filename_base)
                        print(f"  [DEBUG] Guardados {len(keypoints)} frames de keypoints")
                    else:
                        print(f"  [AVISO] No hay keypoints para guardar")
                
            else:
                # PALABRA NO VALIDADA (DESCONOCIDA)
                print(f"  [‚úó NO VALIDADA] No encontrada en rango [{search_start:.2f}s - {search_end:.2f}s]")
                self.failed_count += 1
                
                # Buscar qu√© palabra REAL estaba en ese momento en Whisper
                real_word_data = self.whisper_loader.get_word_at_time(start_time)
                
                if real_word_data:
                    real_word = real_word_data['word']
                    print(f"  [INFO] Palabra real en ese momento: '{real_word}'")
                    folder_name = FileUtils.clean_filename(real_word)
                else:
                    print(f"  [AVISO] No se encontr√≥ ninguna palabra en Whisper en el tiempo {start_time:.2f}s")
                    folder_name = "sin_palabra"
                
                # Crear carpeta con la palabra real
                video_word_folder = self.unknown_videos_dir / folder_name
                keypoints_word_folder = self.unknown_keypoints_dir / folder_name
                
                if video_word_folder.exists():
                    print(f"  [INFO] Carpeta '{folder_name}' ya existe, agregando clip...")
                else:
                    FileUtils.create_folder_if_not_exists(video_word_folder)
                    FileUtils.create_folder_if_not_exists(keypoints_word_folder)
                
                # Calcular tiempos del clip (desde end_time hasta end_time + additional_seconds)
                clip_start = end_time
                clip_end = end_time + self.additional_seconds
                
                print(f"  [INFO] Cortando clip desconocido: {clip_start:.2f}s - {clip_end:.2f}s")
                
                # Cortar clip
                filename = self.video_clipper.cut_clip(clip_start, clip_end, video_word_folder)
                
                # Guardar keypoints DEL SEGMENTO ORIGINAL (no del clip futuro)
                # Los keypoints corresponden al segmento detectado, no al clip desconocido
                if filename:
                    filename_base = filename.replace('.mp4', '')
                    if keypoints:
                        self._save_keypoints(keypoints, keypoints_word_folder, filename_base)
                        print(f"  [DEBUG] Guardados {len(keypoints)} frames de keypoints del segmento detectado")
                    else:
                        print(f"  [AVISO] No hay keypoints para guardar")
    
    def process_remaining_words(self):
        """
        Procesa las palabras restantes de Whisper despu√©s de la √∫ltima detecci√≥n.
        """
        print(f"\n{'='*80}")
        print(f"üìù PROCESANDO PALABRAS RESTANTES DEL WHISPER")
        print(f"{'='*80}")
        
        if not self.detections:
            print("\nNo hab√≠a detecciones para procesar.")
            return
        
        # Encontrar el tiempo de la √∫ltima detecci√≥n
        last_detection_time = max(d['tiempo_fin'] for d in self.detections)
        print(f"\n√öltima detecci√≥n termin√≥ en: {last_detection_time:.2f}s")
        
        # Filtrar palabras de Whisper despu√©s de la √∫ltima detecci√≥n
        remaining_words = [
            w for w in self.whisper_loader.words 
            if w['start'] >= last_detection_time
        ]
        
        if not remaining_words:
            print("\nNo hay palabras restantes despu√©s de la √∫ltima detecci√≥n.")
            return
        
        print(f"Palabras restantes por procesar: {len(remaining_words)}")
        
        for idx, word_data in enumerate(remaining_words):
            real_word = word_data['word']
            word_start = word_data['start']
            word_end = word_data['end']
            
            print(f"\n[{idx + 1}/{len(remaining_words)}] Procesando palabra restante: '{real_word}' ({word_start:.2f}s - {word_end:.2f}s)")
            
            # Crear carpeta con la palabra real
            folder_name = FileUtils.clean_filename(real_word)
            video_word_folder = self.unknown_videos_dir / folder_name
            keypoints_word_folder = self.unknown_keypoints_dir / folder_name
            
            if video_word_folder.exists():
                print(f"  [INFO] Carpeta '{folder_name}' ya existe, agregando clip...")
            else:
                FileUtils.create_folder_if_not_exists(video_word_folder)
                FileUtils.create_folder_if_not_exists(keypoints_word_folder)
            
            # Calcular tiempos del clip
            clip_start = word_end
            clip_end = word_end + self.additional_seconds
            
            print(f"  [INFO] Cortando clip: {clip_start:.2f}s - {clip_end:.2f}s")
            
            # Cortar clip
            filename = self.video_clipper.cut_clip(clip_start, clip_end, video_word_folder)
            if filename:
                self.remaining_processed += 1
                # Guardar keypoints vac√≠os
                filename_base = filename.replace('.mp4', '')
                self._save_keypoints([], keypoints_word_folder, filename_base)
        
        print(f"\nPalabras restantes procesadas: {self.remaining_processed}")
    
    def print_summary(self):
        """Imprime un resumen final del proceso."""
        print(f"\n{'='*80}")
        print(f"‚úÖ PROCESO COMPLETADO")
        print(f"{'='*80}")
        print(f"Total de detecciones procesadas: {len(self.detections)}")
        print(f"  - Validaciones exitosas: {self.validated_count}")
        print(f"  - Validaciones fallidas (desconocidas): {self.failed_count}")
        print(f"Palabras restantes del Whisper procesadas: {self.remaining_processed}")
        print(f"\nClips guardados en:")
        print(f"  - Validadas videos: {self.validated_videos_dir}")
        print(f"  - Validadas keypoints: {self.validated_keypoints_dir}")
        print(f"  - Desconocidas videos: {self.unknown_videos_dir}")
        print(f"  - Desconocidas keypoints: {self.unknown_keypoints_dir}")
        print(f"{'='*80}")


# ======================================================
# FUNCIONES DE ALTO NIVEL
# ======================================================
def predict_latest_video(model_path=None, words_json_path=None, threshold=None):
    """
    Procesa el video m√°s reciente autom√°ticamente.
    
    Args:
        model_path: Path al modelo (opcional, usa config si no se especifica)
        words_json_path: Path al words.json (opcional)
        threshold: Umbral de confianza (opcional)
    
    Returns:
        Lista de detecciones o None si hay error
    """
    if not CONFIG_AVAILABLE:
        print("‚ùå config.py no disponible, no se puede buscar video autom√°ticamente")
        return None
    
    # Obtener rutas del modelo
    if model_path is None or words_json_path is None:
        default_model, default_words = get_model_paths()
        model_path = model_path or default_model
        words_json_path = words_json_path or default_words
    
    # Validar ambiente
    if not validate_environment(check_model=True, check_video=True):
        return None
    
    # Obtener √∫ltimo video
    latest_dir = get_latest_video_dir()
    if not latest_dir:
        print("‚ùå No se encontraron videos procesados")
        return None
    
    files = get_video_files(latest_dir)
    
    print(f"\n{'='*70}")
    print(f"üé¨ VIDEO A PROCESAR")
    print(f"{'='*70}")
    print(f"Directorio: {latest_dir.name}")
    print(f"Keypoints: {files['keypoints'].name}")
    print(f"{'='*70}")
    
    # Crear predictor y procesar
    predictor = SignPredictor(model_path, words_json_path, threshold)
    return predictor.predict_from_json(files['keypoints'])


def predict_from_state():
    """
    Procesa el video indicado en el archivo de estado.
    √ötil cuando data_miner acaba de terminar.
    """
    if not CONFIG_AVAILABLE:
        print("‚ùå config.py no disponible")
        return None
    
    state = load_processing_state()
    if not state:
        print("‚ùå No hay estado guardado")
        print("\nüí° Intenta usar --mode latest para procesar el video m√°s reciente")
        return None
    
    keypoints_path = Path(state['files']['keypoints'])
    if not keypoints_path.exists():
        print(f"‚ùå Archivo de keypoints no existe: {keypoints_path}")
        return None
    
    print(f"\n{'='*70}")
    print(f"üìã USANDO ESTADO GUARDADO")
    print(f"{'='*70}")
    print(f"Timestamp: {state['timestamp']}")
    print(f"Video: {state['video_dir_name']}")
    print(f"{'='*70}")
    
    model_path, words_path = get_model_paths()
    predictor = SignPredictor(model_path, words_path)
    return predictor.predict_from_json(keypoints_path)


def validate_and_clip_pipeline(detections_json, whisper_json, video_path, 
                                validated_videos_dir, validated_keypoints_dir,
                                unknown_videos_dir, unknown_keypoints_dir,
                                search_window=10, additional_seconds=5):
    """
    Pipeline completo de validaci√≥n y corte de clips.
    
    Args:
        detections_json: JSON con detecciones de se√±as
        whisper_json: JSON con transcripci√≥n de Whisper
        video_path: Path al video fuente
        validated_videos_dir: Carpeta para videos validados
        validated_keypoints_dir: Carpeta para keypoints validados
        unknown_videos_dir: Carpeta para videos desconocidos
        unknown_keypoints_dir: Carpeta para keypoints desconocidos
        search_window: Ventana de b√∫squeda hacia atr√°s (segundos)
        additional_seconds: Segundos adicionales despu√©s del fin
    
    Returns:
        SignValidatorAndClipper instance con resultados
    """
    validator = SignValidatorAndClipper(
        detections_json_path=detections_json,
        whisper_json_path=whisper_json,
        video_path=video_path,
        validated_videos_dir=validated_videos_dir,
        validated_keypoints_dir=validated_keypoints_dir,
        unknown_videos_dir=unknown_videos_dir,
        unknown_keypoints_dir=unknown_keypoints_dir,
        search_window_seconds=search_window,
        additional_seconds=additional_seconds
    )
    
    # Validar y cortar clips de detecciones
    validator.validate_and_clip_detections()
    
    # Procesar palabras restantes del Whisper
    validator.process_remaining_words()
    
    # Imprimir resumen final
    validator.print_summary()
    
    return validator


# ======================================================
# MAIN
# ======================================================
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Predictor de se√±as LSM con validaci√≥n y corte de clips')
    
    # Modos de operaci√≥n
    parser.add_argument('--mode', choices=['latest', 'state', 'manual', 'validate'], default='latest',
                       help='Modo de operaci√≥n')
    
    # Par√°metros para predicci√≥n
    parser.add_argument('--keypoints', type=str, help='Ruta manual al JSON de keypoints')
    parser.add_argument('--model', type=str, help='Ruta manual al modelo')
    parser.add_argument('--words', type=str, help='Ruta manual al words.json')
    parser.add_argument('--threshold', type=float, help='Umbral de confianza (0.0-1.0)')
    
    # Par√°metros para validaci√≥n
    parser.add_argument('--detections', type=str, help='JSON con detecciones de se√±as')
    parser.add_argument('--whisper', type=str, help='JSON con transcripci√≥n Whisper')
    parser.add_argument('--video', type=str, help='Ruta al video fuente')
    parser.add_argument('--search-window', type=int, default=10, help='Ventana de b√∫squeda (segundos)')
    parser.add_argument('--additional-seconds', type=int, default=5, help='Segundos adicionales en clips')
    
    # Modo completo (predicci√≥n + validaci√≥n)
    parser.add_argument('--full-pipeline', action='store_true', help='Ejecutar pipeline completo')
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("üöÄ PREDICTOR DE SE√ëAS - VERSI√ìN SIMPLIFICADA")
    print("="*70)
    
    if CONFIG_AVAILABLE:
        ensure_directories()
    
    try:
        # ===== MODO VALIDACI√ìN =====
        if args.mode == 'validate':
            print("\nüìç Modo: Validaci√≥n y corte de clips")
            
            # Paso 2: Validaci√≥n - obtener rutas autom√°ticamente si no se especificaron
            whisper_json = args.whisper
            video_path = args.video

            if not whisper_json or not video_path:
                # Intentar obtener del √∫ltimo video procesado
                auto_whisper, auto_video = get_whisper_and_video_paths()
                whisper_json = whisper_json or auto_whisper
                video_path = video_path or auto_video
                
                if not whisper_json or not video_path:
                    print("\n‚ö† No se pudo encontrar autom√°ticamente whisper/video.")
                    print("   Especifica --whisper y --video manualmente.")
                    print("üíæ Detecciones guardadas. Usa --mode validate para continuar.")
                    sys.exit(0)
                
                print(f"\n‚úì Usando autom√°ticamente:")
                print(f"  Whisper: {whisper_json}")
                print(f"  Video: {video_path}")
            
            validate_and_clip_pipeline(
                detections_json=args.detections,
                whisper_json=whisper_json,
                video_path=video_path,
                validated_videos_dir=VALIDATED_VIDEOS_DIR,
                validated_keypoints_dir=VALIDATED_KEYPOINTS_DIR,
                unknown_videos_dir=UNKNOWN_VIDEOS_DIR,
                unknown_keypoints_dir=UNKNOWN_KEYPOINTS_DIR,
                search_window=args.search_window,
                additional_seconds=args.additional_seconds
            )
        
        # ===== MODO PIPELINE COMPLETO =====
        elif args.full_pipeline:
            print("\nüìç Modo: Pipeline completo (predicci√≥n + validaci√≥n)")
            
            # Paso 1: Predicci√≥n
            if args.mode == 'latest':
                detections = predict_latest_video(
                    model_path=args.model,
                    words_json_path=args.words,
                    threshold=args.threshold
                )
            elif args.mode == 'state':
                detections = predict_from_state()
            elif args.mode == 'manual':
                if not args.keypoints:
                    print("‚ùå Debe especificar --keypoints en modo manual")
                    sys.exit(1)
                
                model_path = args.model
                words_path = args.words
                
                if not model_path and CONFIG_AVAILABLE:
                    model_path, words_path = get_model_paths()
                elif not model_path:
                    print("‚ùå Debe especificar --model en modo manual sin config.py")
                    sys.exit(1)
                
                predictor = SignPredictor(model_path, words_path, args.threshold)
                detections = predictor.predict_from_json(args.keypoints)
            
            if not detections:
                print("‚ùå No se generaron detecciones. Abortando pipeline.")
                sys.exit(1)
            
            # Paso 2: Validaci√≥n - obtener rutas autom√°ticamente
            whisper_json = args.whisper
            video_path = args.video
            
            if not whisper_json or not video_path:
                auto_whisper, auto_video = get_whisper_and_video_paths()
                whisper_json = whisper_json or auto_whisper
                video_path = video_path or auto_video
                
                if not whisper_json or not video_path:
                    print("\n‚ö† No se pudo encontrar autom√°ticamente whisper/video.")
                    print("   Especifica --whisper y --video manualmente.")
                    print("üíæ Detecciones guardadas. Usa --mode validate para continuar.")
                    sys.exit(0)
                
                print(f"\n‚úì Usando autom√°ticamente:")
                print(f"  Whisper: {whisper_json}")
                print(f"  Video: {video_path}")
            
            # Obtener ruta del JSON de detecciones guardado
            output_dir = PREDICTIONS_OUTPUT if CONFIG_AVAILABLE else Path("./output")
            detection_files = sorted(output_dir.glob("detecciones_*.json"))
            if detection_files:
                detections_json = detection_files[-1]
                
                validate_and_clip_pipeline(
                    detections_json=detections_json,
                    whisper_json=whisper_json,
                    video_path=video_path,
                    validated_videos_dir=VALIDATED_VIDEOS_DIR,
                    validated_keypoints_dir=VALIDATED_KEYPOINTS_DIR,
                    unknown_videos_dir=UNKNOWN_VIDEOS_DIR,
                    unknown_keypoints_dir=UNKNOWN_KEYPOINTS_DIR,
                    search_window=args.search_window,
                    additional_seconds=args.additional_seconds
                )
            else:
                print("‚ùå No se encontr√≥ el archivo de detecciones guardado.")
                sys.exit(1)
        
        # ===== MODOS DE SOLO PREDICCI√ìN =====
        else:
            if args.mode == 'latest':
                # Procesar video m√°s reciente
                print("\nüìç Modo: Procesar video m√°s reciente")
                detections = predict_latest_video(
                    model_path=args.model,
                    words_json_path=args.words,
                    threshold=args.threshold
                )
            
            elif args.mode == 'state':
                # Procesar seg√∫n archivo de estado
                print("\nüìç Modo: Usar estado guardado")
                detections = predict_from_state()
            
            elif args.mode == 'manual':
                # Modo manual
                print("\nüìç Modo: Manual")
                if not args.keypoints:
                    print("‚ùå Debe especificar --keypoints en modo manual")
                    sys.exit(1)
                
                model_path = args.model
                words_path = args.words
                
                if not model_path and CONFIG_AVAILABLE:
                    model_path, words_path = get_model_paths()
                elif not model_path:
                    print("‚ùå Debe especificar --model en modo manual sin config.py")
                    sys.exit(1)
                
                predictor = SignPredictor(model_path, words_path, args.threshold)
                detections = predictor.predict_from_json(args.keypoints)
            
            # Mostrar transcript final
            if detections:
                predictor = SignPredictor.__new__(SignPredictor)
                predictor.all_detections = detections
                transcript = predictor.get_transcript()
                
                print(f"\n{'='*70}")
                print(f"üìù TRANSCRIPT COMPLETO")
                print(f"{'='*70}")
                print(transcript)
                print(f"{'='*70}\n")
    
    except KeyboardInterrupt:
        print("\n\n‚ö† Proceso interrumpido por el usuario")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)